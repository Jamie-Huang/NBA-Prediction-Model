{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NBA Model",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jamie-Huang/NBA-Prediction-Model/blob/main/NBA_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlX0PyI1FBry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ac638b-97e8-48df-9915-da8a699f2f9d"
      },
      "source": [
        "!pip install bs4\n",
        "!pip install urlopen\n",
        "from urllib.request import urlopen\n",
        "from google.colab import files\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from google.colab import drive \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import concatenate, Concatenate, Dense, LSTM, Input\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from keras.models import Sequential\n",
        "from keras.models import Functional\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n",
            "Collecting urlopen\n",
            "  Downloading urlopen-1.0.0.zip (2.1 kB)\n",
            "Building wheels for collected packages: urlopen\n",
            "  Building wheel for urlopen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for urlopen: filename=urlopen-1.0.0-py3-none-any.whl size=1409 sha256=f01bdd6d1459d14cfd57b1deef5180343c4d22ae825c74945bf67b425717d147\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/ef/31/96a0d9f1487a5af8b393e88ee04994b20ba0b988c922e3aabd\n",
            "Successfully built urlopen\n",
            "Installing collected packages: urlopen\n",
            "Successfully installed urlopen-1.0.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIBPLVcwcSrl"
      },
      "source": [
        "Load in ELO dataframe, change column types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9Qq4Vw2c6ur"
      },
      "source": [
        "elo_df = pd.read_csv('/content/game_before_elo_df(full).csv')\n",
        "elo_df = elo_df.astype({\"Year\": int, 'Month':int, 'Day':int})\n",
        "elo_df = elo_df.iloc[:,1:]\n",
        "\n",
        "cs = elo_df.columns[:30]\n",
        "\n",
        "main_elo_df = pd.DataFrame(columns = ['Elo', 'Team','Year','Month','Day'])\n",
        "\n",
        "for c in cs:\n",
        "  elo_df[c] = elo_df[c].astype('float')\n",
        "for col in elo_df.columns[:30]:\n",
        "  temp_df = elo_df[col]\n",
        "  temp_df = pd.DataFrame(temp_df)\n",
        "  temp_df['Team'] = col\n",
        "  temp_df.rename(columns={col: 'Elo',}, inplace=True)\n",
        "  temp_df['Year'] = elo_df['Year']\n",
        "  temp_df['Month'] = elo_df['Month']\n",
        "  temp_df['Day'] = elo_df['Day']\n",
        "  main_elo_df = main_elo_df.append(temp_df)\n",
        "main_elo_df.Team = main_elo_df.Team.astype(str)\n",
        "main_elo_df.Year = main_elo_df.Year.astype('int64')\n",
        "main_elo_df.Month = main_elo_df.Month.astype('int64')\n",
        "main_elo_df.Day = main_elo_df.Day.astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNOJw7fIds9e"
      },
      "source": [
        "Joining BoxScores with the ELO rating of each team, downsmapling data to have balanced dataset of wins and losses, hot encode wins and losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXDHJ-lHdAii"
      },
      "source": [
        "df=pd.read_csv('/content/scores.csv')\n",
        "#df = df.reindex(np.random.permutation(df.index))\n",
        "df = df.iloc[:,1:]\n",
        "df = df.iloc[:,:-8]\n",
        "df = df.drop('Home Win',axis=1)\n",
        "df['Home W'] = np.where(df['HT Score'] > df['AT Score'], 1, 0)\n",
        "teams = df['AT Name'].unique().tolist()\n",
        "team_mapping = {'Atlanta Hawks': 'ATL', 'Brooklyn Nets': 'BRK', 'Boston Celtics' : 'BOS', 'Charlotte Bobcats':'CHA','Charlotte Hornets': 'CHH', 'Chicago Bulls': 'CHI', \n",
        "                'Cleveland Cavaliers': 'CLE', 'Dallas Mavericks': 'DAL', 'Denver Nuggets': 'DEN', 'Detroit Pistons': 'DET', 'Golden State Warriors': 'GSW',\n",
        "                'Houston Rockets': 'HOU', 'Indiana Pacers': 'IND', 'Los Angeles Clippers': 'LAC', 'Los Angeles Lakers': 'LAL', 'Memphis Grizzlies': 'MEM',\n",
        "                'Miami Heat': 'MIA', 'Milwaukee Bucks': 'MIL', 'Minnesota Timberwolves': 'MIN', 'New Orleans Hornets': 'NOH', 'New Orleans Pelicans': 'NOP', 'New Jersey Nets': 'BRK',\n",
        "                'New York Knicks': 'NYK', 'Oklahoma City Thunder': 'OKC', 'Orlando Magic': 'ORL', 'Philadelphia 76ers': 'PHI', 'Phoenix Suns': 'PHO', \n",
        "                'Portland Trail Blazers': 'POR','Sacramento Kings': 'SAC', 'San Antonio Spurs': 'SAS', 'Seattle SuperSonics': 'OKC', 'Toronto Raptors': 'TOR',\n",
        "                'Utah Jazz': 'UTA', 'Washington Wizards': 'WAS'}\n",
        "df['HT Abbrev'] = df['HT Name'].map(team_mapping)\n",
        "df['AT Abbrev'] = df['AT Name'].map(team_mapping)\n",
        "df = df.reset_index()\n",
        "df = df.rename(columns={\"index\":\"New_ID\"})\n",
        "df['New_ID'] = df.index + 1\n",
        "df.Year = df.Year.astype('int64')\n",
        "df.Month = df.Month.astype('int64')\n",
        "df.Day = df.Day.astype('int64')\n",
        "\n",
        "\n",
        "df = pd.merge(df,main_elo_df,left_on= ['HT Abbrev','Year','Month','Day'],right_on = ['Team','Year','Month','Day'])\n",
        "df = df.iloc[:,:-1]\n",
        "df.columns = [*df.columns[:-1], 'HT Elo']\n",
        "\n",
        "df = pd.merge(df,main_elo_df,left_on= ['AT Abbrev','Year','Month','Day'],right_on = ['Team','Year','Month','Day'])\n",
        "main_df = df\n",
        "df = df.iloc[:,:-1]\n",
        "df.columns = [*df.columns[:-1], 'AT Elo']\n",
        "home_w = df[df['Home W'] == 1].iloc[:608,:]\n",
        "away_w = df[df['Home W'] == 0]\n",
        "away_w = away_w.append(home_w)\n",
        "df = away_w\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "\n",
        "output_df = df['Home W']\n",
        "test_df = output_df\n",
        "\n",
        "output_df = output_df.values.flatten()\n",
        "input_df = df.iloc[:,9:]\n",
        "input_df = input_df.drop('AT W/L Percentage',axis=1)\n",
        "input_df = input_df.drop('HT W/L Percentage',axis=1)\n",
        "input_df = input_df.drop('PS HT W/L Percentage',axis=1)\n",
        "testing_df = input_df\n",
        "input_df = input_df.drop('HT Abbrev',axis=1)\n",
        "input_df = input_df.drop('AT Abbrev',axis=1)\n",
        "input_df = input_df.drop('Home W',axis=1)\n",
        "y_train = tf.one_hot(output_df, depth=1,dtype='int8')\n",
        "input_df.fillna(0,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2YXw2IxfUTk"
      },
      "source": [
        "Rescaling all data to values between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDkBQJPxF9zU"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaled_input = scaler.fit_transform(input_df)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re7xHo_PwFOo"
      },
      "source": [
        "rescaled_input = pd.DataFrame(data=rescaled_input, columns=input_df.columns)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJrH_IIw9oqC"
      },
      "source": [
        "l = list(input_df.columns)\n",
        "home_features = l[2:148] + [l[-2]]\n",
        "home_input_df = input_df[home_features]\n",
        "\n",
        "away_features = l[0:2] + l[148:-2] + [l[-1]]\n",
        "away_input_df = input_df[away_features]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIzYT9Z0fale"
      },
      "source": [
        "Model with 2 inputs (for home and away teams)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCHAiE2KTbRH"
      },
      "source": [
        "ht_input = keras.Input(\n",
        "    shape=(147,), name=\"Home Team\"\n",
        ") \n",
        "\n",
        "dense = layers.Dense(200, activation=\"relu\")\n",
        "connect_ht = dense(ht_input)\n",
        "\n",
        "outputs_ht = layers.Dense(100,activation='relu')(connect_ht)\n",
        "\n",
        "at_input = keras.Input(\n",
        "    shape=(147,), name=\"Away Team\"\n",
        ") \n",
        "\n",
        "dense = layers.Dense(200, activation=\"relu\")\n",
        "connect_at = dense(at_input)\n",
        "\n",
        "\n",
        "\n",
        "outputs_at = layers.Dense(100,activation=\"relu\")(connect_at)\n",
        "\n",
        "model_ht = keras.Model(inputs=ht_input, outputs=outputs_ht, name=\"model_ht\")\n",
        "model_at = keras.Model(inputs=at_input, outputs=outputs_at, name='model_at')\n",
        "\n",
        "combinedInput = concatenate([model_ht.output, model_at.output])\n",
        "\n",
        "layer4 = layers.Dense(25,activation= 'relu')(combinedInput)\n",
        "output_layer = layers.Dense(1,activation= 'sigmoid')(layer4)\n",
        "\n",
        "model = keras.Model(inputs =[model_ht.input,model_at.input],outputs= output_layer)\n",
        "\n",
        "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer='Adam', metrics= ['accuracy'])\n",
        "history = model.fit(x=[home_input_df,away_input_df], y = y_train, epochs= 200, batch_size=370,validation_split=0.2,shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqhaHOqxF-tO"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(Dense(294, input_dim=294, activation= 'relu'))\n",
        "model.add(Dense(300,activation= 'relu'))\n",
        "model.add(Dense(110,activation= 'relu'))\n",
        "model.add(Dense(25,activation= 'relu'))\n",
        "model.add(Dense(1, activation= 'sigmoid'))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW879bHCin4K"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer= 'Adam' , metrics=['accuracy',AUC(num_thresholds=400)])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDG27jfxhEHu"
      },
      "source": [
        "history = model.fit(rescaled_input, y_train, epochs= 200, batch_size=37,validation_split=0.2,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-aqnKORj4u9"
      },
      "source": [
        "loss_train = history.history['accuracy']\n",
        "\n",
        "loss_val = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(200)\n",
        "\n",
        "plt.plot(epochs, loss_train, 'g', label='Training Accuracy')\n",
        "\n",
        "plt.plot(epochs, loss_val, 'b', label='Validation Accuracy')\n",
        "\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}